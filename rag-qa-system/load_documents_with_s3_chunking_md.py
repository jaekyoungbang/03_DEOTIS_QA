#!/usr/bin/env python3
"""
í†µí•© ë¬¸ì„œ ë¡œë”© ì‹œìŠ¤í…œ - s3-chunking MD íŒŒì¼ ìš°ì„ 
- s3 í´ë”: ê¸°ë³¸ ì²­í‚¹ìœ¼ë¡œ Word/PDF ë¬¸ì„œ ì²˜ë¦¬
- s3-chunking í´ë”: ìµœì í™”ëœ MD íŒŒì¼ë§Œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ê²½ë¡œ í¬í•¨)
"""

import os
import sys
from pathlib import Path
import time
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.document_processor import DocumentProcessor
from services.chunking_strategies import get_chunking_strategy
from models.embeddings import EmbeddingManager
from models.vectorstore import DualVectorStoreManager
from config import Config

# s3-chunking MD ë¡œë” import
from load_s3_chunking_md import S3ChunkingMDLoader


def load_all_documents_with_md_priority(clear_before_load=True):
    """s3-chunking MD íŒŒì¼ì„ ìš°ì„ ìœ¼ë¡œ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ"""
    
    print("ğŸš€ í†µí•© ë¬¸ì„œ ë¡œë”© ì‹œìŠ¤í…œ ì‹œì‘ (MD íŒŒì¼ ìš°ì„ )...")
    print("=" * 60)
    
    start_time = time.time()
    
    # S3 í´ë”ë“¤ ê²½ë¡œ ì„¤ì •
    import platform
    if platform.system() == "Windows" or os.name == "nt":
        s3_folders = {
            "s3": r"D:\99_DEOTIS_QA_SYSTEM\03_DEOTIS_QA\s3",
            "s3-chunking": r"D:\99_DEOTIS_QA_SYSTEM\03_DEOTIS_QA\s3-chunking"
        }
        print("ğŸªŸ Windows í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
    else:
        s3_folders = {
            "s3": "/mnt/d/99_DEOTIS_QA_SYSTEM/03_DEOTIS_QA/s3",
            "s3-chunking": "/mnt/d/99_DEOTIS_QA_SYSTEM/03_DEOTIS_QA/s3-chunking"
        }
        print("ğŸ§ WSL/Linux í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì˜µì…˜)
    if clear_before_load:
        print("\nğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„° DB ë°ì´í„° ì‚­ì œ ì¤‘...")
        try:
            from models.vectorstore import reset_vectorstore
            reset_vectorstore()
            print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    # 1ë‹¨ê³„: s3-chunking MD íŒŒì¼ ë¡œë“œ (ìš°ì„ ìˆœìœ„)
    print("\n" + "="*60)
    print("ğŸ“ 1ë‹¨ê³„: s3-chunking MD íŒŒì¼ ë¡œë“œ")
    print("="*60)
    
    try:
        md_loader = S3ChunkingMDLoader()
        # clear_before_load=Falseë¡œ ì„¤ì • (ì´ë¯¸ ìœ„ì—ì„œ ì‚­ì œí•¨)
        md_loader.load_s3_chunking_md_files(clear_before_load=False)
        print("âœ… s3-chunking MD íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ s3-chunking MD íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    # 2ë‹¨ê³„: s3 í´ë” ì¼ë°˜ ë¬¸ì„œ ë¡œë“œ
    print("\n" + "="*60)
    print("ğŸ“ 2ë‹¨ê³„: s3 í´ë” ì¼ë°˜ ë¬¸ì„œ ë¡œë“œ")
    print("="*60)
    
    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    doc_processor = DocumentProcessor()
    embedding_manager = EmbeddingManager()
    vectorstore_manager = DualVectorStoreManager(embedding_manager.get_embeddings())
    
    # ì§€ì›ë˜ëŠ” íŒŒì¼ í™•ì¥ì (MD ì œì™¸)
    supported_extensions = ['.txt', '.docx', '.pdf']  # MDëŠ” ì´ë¯¸ ì²˜ë¦¬ë¨
    
    total_documents_loaded = 0
    total_chunks = 0
    
    # s3 í´ë” ì²˜ë¦¬
    s3_folder = s3_folders["s3"]
    if os.path.exists(s3_folder):
        print(f"\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {s3_folder}")
        
        for root, dirs, files in os.walk(s3_folder):
            for file in files:
                file_path = os.path.join(root, file)
                file_extension = os.path.splitext(file)[1].lower()
                
                # ì„ì‹œ íŒŒì¼ ì œì™¸
                if file.startswith('~$') or file.startswith('.'):
                    continue
                
                if file_extension in supported_extensions:
                    print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {file}")
                    
                    try:
                        # ë¬¸ì„œ ë¡œë“œ
                        documents = doc_processor.load_document(file_path)
                        
                        if not documents:
                            print(f"   âš ï¸ ë¬¸ì„œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                            continue
                        
                        # ê¸°ë³¸ ì²­í‚¹ ì „ëµ ì ìš©
                        strategy = get_chunking_strategy('basic')
                        chunks = strategy.split_documents(documents)
                        
                        # ë©”íƒ€ë°ì´í„° ë³´ê°•
                        for chunk in chunks:
                            chunk.metadata.update({
                                'source': file_path,
                                'filename': file,
                                'folder_type': 's3',
                                'processing_strategy': 'basic_chunking'
                            })
                        
                        # ë²¡í„° DBì— ì €ì¥
                        vectorstore_manager.add_documents(chunks, "basic")
                        
                        print(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ (basic ì»¬ë ‰ì…˜)")
                        
                        total_documents_loaded += 1
                        total_chunks += len(chunks)
                        
                    except Exception as e:
                        print(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    # ìµœì¢… í†µê³„
    try:
        counts = vectorstore_manager.get_document_count()
        print(f"\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ì €ì¥ í†µê³„:")
        print("="*60)
        print(f"   - ê¸°ë³¸ ì²­í‚¹ (s3): {counts.get('basic', 0)}ê°œ")
        print(f"   - MD ìµœì í™” ì²­í‚¹ (s3-chunking): {counts.get('custom', 0)}ê°œ")
        print(f"   - ì „ì²´: {counts.get('total', 0)}ê°œ")
    except Exception as e:
        print(f"âš ï¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
    print(f"\nğŸ‰ í†µí•© ë¬¸ì„œ ë¡œë”© ì™„ë£Œ!")
    
    return total_documents_loaded, total_chunks


def verify_image_support():
    """ì´ë¯¸ì§€ ì§€ì› í™•ì¸"""
    print("\nğŸ” ì´ë¯¸ì§€ ì§€ì› í™•ì¸...")
    
    try:
        from models.vectorstore import DualVectorStoreManager
        from models.embeddings import EmbeddingManager
        
        embedding_manager = EmbeddingManager()
        vectorstore_manager = DualVectorStoreManager(embedding_manager.get_embeddings())
        
        # ì´ë¯¸ì§€ ê´€ë ¨ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        test_query = "ì´ë¯¸ì§€"
        results = vectorstore_manager.similarity_search_with_score(test_query, "custom", k=3)
        
        image_chunks = 0
        for doc, score in results:
            if doc.metadata.get('has_images', False):
                image_chunks += 1
                print(f"\nâœ… ì´ë¯¸ì§€ í¬í•¨ ì²­í¬ ë°œê²¬:")
                print(f"   - ì„¹ì…˜: {doc.metadata.get('section', 'N/A')}")
                print(f"   - ì´ë¯¸ì§€ ìˆ˜: {len(doc.metadata.get('images', []))}")
                for img in doc.metadata.get('images', [])[:2]:  # ì²˜ìŒ 2ê°œë§Œ í‘œì‹œ
                    print(f"   - ê²½ë¡œ: {img['path']}")
        
        if image_chunks == 0:
            print("âš ï¸ ì´ë¯¸ì§€ í¬í•¨ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"\nâœ… ì´ {image_chunks}ê°œì˜ ì´ë¯¸ì§€ í¬í•¨ ì²­í¬ í™•ì¸")
            
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì§€ì› í™•ì¸ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    print("ğŸ¯ í†µí•© ë¬¸ì„œ ë¡œë”© ì‹œìŠ¤í…œ")
    print("   - s3: Word/PDF ë¬¸ì„œ (ê¸°ë³¸ ì²­í‚¹)")
    print("   - s3-chunking: ìµœì í™”ëœ MD íŒŒì¼ (ì´ë¯¸ì§€ ê²½ë¡œ í¬í•¨)")
    print()
    
    # ë¬¸ì„œ ë¡œë”© ì‹¤í–‰
    docs_loaded, chunks_created = load_all_documents_with_md_priority(clear_before_load=True)
    
    # ì´ë¯¸ì§€ ì§€ì› í™•ì¸
    verify_image_support()
    
    print("\nğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ:")
    print("   - ëª¨ë“œ 1: ì‚¬ë‚´ì„œë²„ vLLM + s3-ê¸°ë³¸")
    print("   - ëª¨ë“œ 2: ì‚¬ë‚´ì„œë²„ vLLM + s3-chunking (MD ìµœì í™”)")
    print("   - ëª¨ë“œ 3: ChatGPT + s3-ê¸°ë³¸")
    print("   - ëª¨ë“œ 4: ChatGPT + s3-chunking (MD ìµœì í™”)")
    print("\n   â¡ï¸ s3-chunking ëª¨ë“œì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œ ì •ë³´ë„ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤.")