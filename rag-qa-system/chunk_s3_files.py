#!/usr/bin/env python3
"""
S3-CHUNKING í´ë”ì˜ íŒŒì¼ë“¤ì„ /$$/ êµ¬ë¶„ìë¡œ ì²­í‚¹í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
from docx import Document
import json

def chunk_docx_file(file_path, delimiter="/$$/"):
    """DOCX íŒŒì¼ì„ êµ¬ë¶„ì ê¸°ì¤€ìœ¼ë¡œ ì²­í‚¹"""
    try:
        doc = Document(file_path)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = []
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if text:
                full_text.append(text)
        
        # í…ìŠ¤íŠ¸ ê²°í•©
        combined_text = '\n'.join(full_text)
        
        # êµ¬ë¶„ìë¡œ ì²­í‚¹
        if delimiter in combined_text:
            chunks = combined_text.split(delimiter)
            print(f"âœ… {os.path.basename(file_path)}: {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨ (êµ¬ë¶„ì: {delimiter})")
            return chunks
        else:
            print(f"âš ï¸  {os.path.basename(file_path)}: êµ¬ë¶„ì '{delimiter}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
            return [combined_text]
            
    except Exception as e:
        print(f"âŒ {file_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []

def add_delimiter_to_docx(file_path, output_path, sections, delimiter="/$$/"):
    """DOCX íŒŒì¼ì— êµ¬ë¶„ìë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥"""
    try:
        doc = Document(file_path)
        new_doc = Document()
        
        # ë¬¸ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ì–´ êµ¬ë¶„ì ì¶”ê°€
        current_section = []
        section_keywords = sections  # ì„¹ì…˜ì„ ë‚˜ëˆ„ëŠ” í‚¤ì›Œë“œë“¤
        
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            
            # ì„¹ì…˜ í‚¤ì›Œë“œë¥¼ ì°¾ìœ¼ë©´
            is_section_start = False
            for keyword in section_keywords:
                if keyword in text:
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    if current_section:
                        for para_text in current_section:
                            new_doc.add_paragraph(para_text)
                        # êµ¬ë¶„ì ì¶”ê°€
                        new_doc.add_paragraph(delimiter)
                        current_section = []
                    is_section_start = True
                    break
            
            # í˜„ì¬ ë‹¨ë½ ì¶”ê°€
            if text:
                current_section.append(text)
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section:
            for para_text in current_section:
                new_doc.add_paragraph(para_text)
        
        # íŒŒì¼ ì €ì¥
        new_doc.save(output_path)
        print(f"âœ… êµ¬ë¶„ìê°€ ì¶”ê°€ëœ íŒŒì¼ ì €ì¥ë¨: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ êµ¬ë¶„ì ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def process_s3_chunking_folder():
    """s3-chunking í´ë”ì˜ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬"""
    s3_folder = "/mnt/d/99_DEOTIS_QA_SYSTEM/03_DEOTIS_QA/s3-chunking"
    output_folder = "/mnt/d/99_DEOTIS_QA_SYSTEM/03_DEOTIS_QA/rag-qa-system/data/chunked_documents"
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_folder, exist_ok=True)
    
    print("="*60)
    print("S3-CHUNKING í´ë” íŒŒì¼ ì²­í‚¹ ì‹œì‘")
    print("="*60)
    
    # BCì¹´ë“œ ë¬¸ì„œë¥¼ ìœ„í•œ ì„¹ì…˜ í‚¤ì›Œë“œ ì •ì˜
    bc_card_sections = [
        "1. ê°œìš”",
        "2. ì‹ ìš©ì¹´ë“œ ë°œê¸‰",
        "3. ì¹´ë“œ ì´ìš©",
        "4. ê²°ì œ",
        "5. ë¶€ê°€ì„œë¹„ìŠ¤",
        "6. ê³ ê°ì„œë¹„ìŠ¤",
        "ì œ1ì¥",
        "ì œ2ì¥",
        "ì œ3ì¥",
        "ì œ4ì¥",
        "ì œ5ì¥",
        "â– ",  # ì£¼ìš” ì„¹ì…˜ ë§ˆì»¤
        "â–¶",  # ì„œë¸Œ ì„¹ì…˜ ë§ˆì»¤
    ]
    
    # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
    for filename in os.listdir(s3_folder):
        if filename.endswith('.docx'):
            file_path = os.path.join(s3_folder, filename)
            
            print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {filename}")
            
            # 1. ì›ë³¸ íŒŒì¼ ì²­í‚¹ ì‹œë„
            chunks = chunk_docx_file(file_path)
            
            # 2. êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if len(chunks) <= 1:
                print(f"ğŸ’¡ êµ¬ë¶„ìë¥¼ ì¶”ê°€í•˜ì—¬ ì¬ì²­í‚¹ ì‹œë„...")
                
                # êµ¬ë¶„ìê°€ ì¶”ê°€ëœ ìƒˆ íŒŒì¼ ìƒì„±
                modified_filename = f"chunked_{filename}"
                modified_path = os.path.join(output_folder, modified_filename)
                
                if add_delimiter_to_docx(file_path, modified_path, bc_card_sections):
                    # ìˆ˜ì •ëœ íŒŒì¼ ë‹¤ì‹œ ì²­í‚¹
                    chunks = chunk_docx_file(modified_path)
            
            # 3. ì²­í‚¹ ê²°ê³¼ ì €ì¥
            if chunks and len(chunks) > 1:
                result_filename = f"{filename.replace('.docx', '')}_chunks.json"
                result_path = os.path.join(output_folder, result_filename)
                
                chunk_data = {
                    'source_file': filename,
                    'delimiter': "/$$/",
                    'chunk_count': len(chunks),
                    'chunks': []
                }
                
                for i, chunk in enumerate(chunks):
                    chunk_info = {
                        'index': i,
                        'content': chunk.strip(),
                        'length': len(chunk.strip())
                    }
                    chunk_data['chunks'].append(chunk_info)
                
                # JSONìœ¼ë¡œ ì €ì¥
                with open(result_path, 'w', encoding='utf-8') as f:
                    json.dump(chunk_data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… ì²­í‚¹ ê²°ê³¼ ì €ì¥: {result_filename}")
                
                # ì²­í¬ ìš”ì•½ ì¶œë ¥
                print(f"   - ì´ ì²­í¬ ìˆ˜: {len(chunks)}")
                for i, chunk in enumerate(chunks[:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
                    preview = chunk.strip()[:100] + "..." if len(chunk.strip()) > 100 else chunk.strip()
                    print(f"   - ì²­í¬ {i+1}: {preview}")
                
                if len(chunks) > 3:
                    print(f"   ... ì™¸ {len(chunks)-3}ê°œ ì²­í¬")

if __name__ == "__main__":
    process_s3_chunking_folder()