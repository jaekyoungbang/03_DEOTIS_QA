"""
í–¥ìƒëœ ë¡œê¹… ì‹œìŠ¤í…œ
- Redis/MySQL ì‘ì—… ë¡œê·¸ë¥¼ ì§ê´€ì ìœ¼ë¡œ í‘œì‹œ
- ìƒ‰ìƒ ì½”ë”© ë° ì•„ì´ì½˜ ì‚¬ìš©
- êµ¬ì¡°í™”ëœ ë¡œê·¸ í¬ë§·
"""

import logging
import sys
from datetime import datetime
from typing import Dict, Any, Optional
import json

class ColorFormatter(logging.Formatter):
    """ìƒ‰ìƒì´ ì ìš©ëœ ë¡œê·¸ í¬ë§·í„°"""
    
    # ANSI ìƒ‰ìƒ ì½”ë“œ
    COLORS = {
        'DEBUG': '\033[36m',     # ì²­ë¡ìƒ‰
        'INFO': '\033[32m',      # ì´ˆë¡ìƒ‰
        'WARNING': '\033[33m',   # ë…¸ë€ìƒ‰
        'ERROR': '\033[31m',     # ë¹¨ê°„ìƒ‰
        'CRITICAL': '\033[35m',  # ë³´ë¼ìƒ‰
        'RESET': '\033[0m'       # ë¦¬ì…‹
    }
    
    # ë ˆë²¨ë³„ ì•„ì´ì½˜
    ICONS = {
        'DEBUG': 'ğŸ”',
        'INFO': 'âœ…',
        'WARNING': 'âš ï¸',
        'ERROR': 'âŒ',
        'CRITICAL': 'ğŸš¨'
    }
    
    def format(self, record):
        # ìƒ‰ìƒ ë° ì•„ì´ì½˜ ì ìš©
        color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        icon = self.ICONS.get(record.levelname, 'ğŸ“')
        reset = self.COLORS['RESET']
        
        # ì‹œê°„ í¬ë§·
        timestamp = datetime.fromtimestamp(record.created).strftime('%H:%M:%S')
        
        # ë¡œê·¸ ë©”ì‹œì§€ í¬ë§·
        log_message = f"{color}{icon} [{timestamp}] {record.levelname}{reset} - {record.getMessage()}"
        
        return log_message

class EnhancedLogger:
    """í–¥ìƒëœ ë¡œê±° í´ë˜ìŠ¤"""
    
    def __init__(self, name: str = "RAG_QA_SYSTEM"):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.DEBUG)
        console_handler.setFormatter(ColorFormatter())
        
        self.logger.addHandler(console_handler)
        self.logger.propagate = False
    
    def redis_operation(self, operation: str, query: str, result: Any = None, 
                       error: Optional[str] = None, duration: Optional[float] = None):
        """Redis ì‘ì—… ë¡œê·¸"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        if error:
            self.logger.error(f"ğŸ”´ REDIS [{operation}] FAILED")
            self.logger.error(f"   ğŸ“ Query: \"{query_preview}\"")
            self.logger.error(f"   âŒ Error: {error}")
        else:
            status_icon = "ğŸ¯" if operation == "HIT" else "ğŸ’¾" if operation == "SET" else "ğŸ“Š" if operation == "STATS" else "ğŸ”¢" if operation == "COUNT" else "ğŸ“‹"
            self.logger.info(f"{status_icon} REDIS [{operation}] SUCCESS")
            self.logger.info(f"   ğŸ“ Query: \"{query_preview}\"")
            
            if duration:
                self.logger.info(f"   â±ï¸  Duration: {duration:.3f}s")
            
            if operation == "HIT" and result:
                cached_time = result.get('cached_at', 'Unknown')
                access_count = result.get('access_count', 1)
                self.logger.info(f"   ğŸ• Cached at: {cached_time}")
                self.logger.info(f"   ğŸ‘¥ Access count: {access_count} times")
                
            elif operation == "SET" and result:
                similarity = result.get('similarity_score', 0)
                ttl = result.get('ttl', '1 hour')
                self.logger.info(f"   ğŸ“ˆ Similarity: {similarity:.1%}")
                self.logger.info(f"   â° TTL: {ttl}")
                self.logger.info(f"   âœ… ğŸ”¥ CACHED for fast future access!")
                
            elif operation == "COUNT" and result:
                count = result.get('current_count', 0)
                ttl = result.get('ttl', '1 hour')
                self.logger.info(f"   ğŸ”¢ Search count: {count} times")
                self.logger.info(f"   â° TTL: {ttl}")
                
                if count >= 5:
                    self.logger.info(f"   ğŸ¯ â­ POPULAR THRESHOLD REACHED! (5+ searches)")
                elif count >= 3:
                    self.logger.info(f"   ğŸ“ˆ Getting popular... ({count}/5)")
                
            elif operation == "STATS" and result:
                self.logger.info(f"   ğŸ“Š Cached queries: {result.get('cached_queries', 0)}")
                self.logger.info(f"   ğŸ”¢ Total searches: {result.get('total_searches', 0)}")
                self.logger.info(f"   â­ Popular queries: {result.get('popular_queries', 0)}")
    
    def mysql_operation(self, operation: str, query: str = "", result: Any = None, 
                       error: Optional[str] = None, count: Optional[int] = None):
        """MySQL ì‘ì—… ë¡œê·¸"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        if error:
            self.logger.error(f"ğŸ”´ MYSQL [{operation}] FAILED")
            if query:
                self.logger.error(f"   ğŸ“ Query: \"{query_preview}\"")
            self.logger.error(f"   âŒ Error: {error}")
        else:
            status_icon = "ğŸ’«" if operation == "INSERT" else "ğŸ“‹" if operation == "SELECT" else "ğŸ—‘ï¸" if operation == "DELETE" else "ğŸ”§"
            self.logger.info(f"{status_icon} MYSQL [{operation}] SUCCESS")
            
            if query:
                self.logger.info(f"   ğŸ“ Query: \"{query_preview}\"")
            
            if operation == "INSERT" and count:
                search_count = count
                category = result.get('category', 'unknown') if result else 'unknown'
                similarity = result.get('similarity', 0.0) if result else 0.0
                
                self.logger.info(f"   ğŸ”¢ Search count: {search_count} times")
                self.logger.info(f"   ğŸ“‚ Category: {category}")
                self.logger.info(f"   ğŸ“ˆ Similarity: {similarity:.1%}")
                self.logger.info(f"   âœ… ğŸ¯ SAVED TO POPULAR QUESTIONS DATABASE!")
                
                # ì¸ê¸°ë„ì— ë”°ë¥¸ ì¶”ê°€ ë©”ì‹œì§€
                if search_count >= 10:
                    self.logger.info(f"   ğŸ”¥ ğŸŒŸ SUPER POPULAR QUESTION! ({search_count} searches)")
                elif search_count >= 7:
                    self.logger.info(f"   ğŸ”¥ Very popular question ({search_count} searches)")
                else:
                    self.logger.info(f"   ğŸ“ˆ Popular question ({search_count} searches)")
                
            elif operation == "SELECT" and result:
                if isinstance(result, list):
                    self.logger.info(f"   ğŸ“‹ Found: {len(result)} popular questions")
                    if result:
                        self.logger.info(f"   ğŸ† Top question: \"{result[0].get('query', '')[:40]}...\"")
                elif isinstance(result, dict):
                    total_q = result.get('total_questions', 0)
                    total_s = result.get('total_searches', 0)
                    avg_sim = result.get('avg_similarity', 0.0)
                    self.logger.info(f"   ğŸ“Š Total questions: {total_q}")
                    self.logger.info(f"   ğŸ”¢ Total searches: {total_s}")
                    self.logger.info(f"   ğŸ“ˆ Average similarity: {avg_sim:.1%}")
                    
            elif operation == "DELETE" and count is not None:
                self.logger.info(f"   ğŸ—‘ï¸  Deleted records: {count}")
                if count > 0:
                    self.logger.info(f"   âœ… Database cleared successfully!")
    
    def system_operation(self, operation: str, component: str, status: str, 
                        details: Optional[Dict] = None, error: Optional[str] = None):
        """ì‹œìŠ¤í…œ ì‘ì—… ë¡œê·¸"""
        if error or status == "FAILED":
            self.logger.error(f"ğŸš¨ SYSTEM [{component}] {operation} FAILED")
            if error:
                self.logger.error(f"   âŒ Error: {error}")
        else:
            status_icon = "ğŸš€" if operation == "INIT" else "ğŸ”„" if operation == "UPDATE" else "ğŸ›‘" if operation == "SHUTDOWN" else "âš™ï¸"
            self.logger.info(f"{status_icon} SYSTEM [{component}] {operation} {status}")
            
            if details:
                for key, value in details.items():
                    icon = "ğŸ“Š" if "count" in key.lower() or "stat" in key.lower() else "ğŸ”—" if "connect" in key.lower() else "ğŸ“"
                    self.logger.info(f"   {icon} {key.title()}: {value}")
    
    def search_operation(self, query: str, similarity: float, source: str, 
                        cached: bool = False, duration: Optional[float] = None):
        """ê²€ìƒ‰ ì‘ì—… ë¡œê·¸"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        cache_icon = "ğŸ¯" if cached else "ğŸ”"
        similarity_icon = "ğŸŸ¢" if similarity >= 0.8 else "ğŸŸ¡" if similarity >= 0.6 else "ğŸ”´"
        
        self.logger.info(f"{cache_icon} SEARCH {'[CACHED]' if cached else '[VECTOR]'}")
        self.logger.info(f"   ğŸ“ Query: \"{query_preview}\"")
        self.logger.info(f"   {similarity_icon} Similarity: {similarity:.1%}")
        self.logger.info(f"   ğŸ“‚ Source: {source}")
        
        if duration:
            self.logger.info(f"   â±ï¸  Duration: {duration:.3f}s")
    
    def question_flow(self, query: str, flow_type: str, details: Dict):
        """ì§ˆë¬¸ ì²˜ë¦¬ í”Œë¡œìš° ë¡œê·¸"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        if flow_type == "START":
            request_count = details.get('request_count', 0)
            self.logger.info(f"ğŸ¬ QUESTION PROCESSING START")
            self.logger.info(f"   ğŸ“ Query: \"{query_preview}\"")
            if request_count > 0:
                self.logger.info(f"   ğŸ”¢ Request #{request_count} for this query")
            
        elif flow_type == "CACHE_CHECK":
            hit = details.get('hit', False)
            if hit:
                self.logger.info(f"ğŸ¯ CACHE HIT - Returning cached result")
            else:
                self.logger.info(f"âŒ CACHE MISS - Proceeding to vector search")
                
        elif flow_type == "VECTOR_SEARCH":
            similarity = details.get('similarity', 0)
            self.logger.info(f"ğŸ” VECTOR SEARCH COMPLETED")
            self.logger.info(f"   ğŸ“ˆ Max similarity: {similarity:.1%}")
            
        elif flow_type == "LLM_REQUEST":
            self.logger.info(f"ğŸ¤– REQUESTING LLM GENERATION")
            self.logger.info(f"   ğŸ“ Query: \"{query_preview}\"")
            self.logger.info(f"   ğŸ”„ Generating response with AI model...")
            
        elif flow_type == "LLM_RESPONSE":
            response_length = details.get('response_length', 0)
            duration = details.get('duration', 0)
            self.logger.info(f"ğŸ¤– LLM RESPONSE RECEIVED")
            self.logger.info(f"   ğŸ“ Response length: {response_length} characters")
            if duration > 0:
                self.logger.info(f"   â±ï¸  Generation time: {duration:.3f}s")
            
        elif flow_type == "RESPONSE_TYPE":
            response_type = details.get('type', 'unknown')
            threshold_met = details.get('threshold_met', False)
            
            if response_type == "normal":
                self.logger.info(f"âœ… NORMAL RESPONSE - High similarity")
            elif response_type == "low_similarity":
                show_buttons = details.get('show_popular_buttons', False)
                if show_buttons:
                    self.logger.info(f"ğŸ”˜ LOW SIMILARITY - Showing popular question buttons")
                else:
                    self.logger.info(f"ğŸ’¡ LOW SIMILARITY - Showing suggested questions")
            elif response_type == "cached":
                self.logger.info(f"âš¡ CACHED RESPONSE - Lightning fast!")
            else:
                self.logger.info(f"ğŸ“‹ {response_type.upper()} RESPONSE")
                
        elif flow_type == "END":
            cached = details.get('cached', False)
            popular_saved = details.get('popular_saved', False)
            total_requests = details.get('total_requests', 0)
            
            self.logger.info(f"ğŸ QUESTION PROCESSING END")
            if cached:
                self.logger.info(f"   ğŸ’¾ âœ… RESULT CACHED for future speed boost!")
            if popular_saved:
                self.logger.info(f"   â­ âœ… ADDED TO POPULAR QUESTIONS DATABASE!")
            if total_requests > 0:
                self.logger.info(f"   ğŸ“Š Total requests for this query: {total_requests}")
    
    def performance_metrics(self, operation: str, metrics: Dict):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸"""
        self.logger.info(f"ğŸ“Š PERFORMANCE [{operation}]")
        
        for key, value in metrics.items():
            if 'time' in key.lower() or 'duration' in key.lower():
                icon = "â±ï¸"
                if isinstance(value, float):
                    value_str = f"{value:.3f}s"
                else:
                    value_str = str(value)
            elif 'count' in key.lower():
                icon = "ğŸ”¢"
                value_str = str(value)
            elif 'size' in key.lower():
                icon = "ğŸ“¦"
                value_str = str(value)
            else:
                icon = "ğŸ“"
                value_str = str(value)
                
            self.logger.info(f"   {icon} {key.replace('_', ' ').title()}: {value_str}")
    
    def separator(self, title: str = ""):
        """êµ¬ë¶„ì„  ì¶œë ¥"""
        if title:
            line = "=" * 20 + f" {title} " + "=" * 20
        else:
            line = "=" * 60
        self.logger.info(line)
    
    def structured_log_box(self, title: str, data: Dict, box_type: str = "INFO"):
        """ì •í˜•í™”ëœ ë°•ìŠ¤ í˜•íƒœ ë¡œê·¸"""
        # ë°•ìŠ¤ ë„ˆë¹„ ê³„ì‚°
        max_width = max(len(title), max(len(f"{k}: {v}") for k, v in data.items()) if data else 0) + 4
        box_width = max(max_width, 50)
        
        # ë°•ìŠ¤ ì•„ì´ì½˜ ì„ íƒ
        box_icons = {
            "REDIS": "ğŸ’¾",
            "MYSQL": "ğŸ—„ï¸", 
            "SYSTEM": "âš™ï¸",
            "SEARCH": "ğŸ”",
            "INFO": "ğŸ“‹",
            "ERROR": "âŒ",
            "SUCCESS": "âœ…"
        }
        icon = box_icons.get(box_type, "ğŸ“‹")
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        horizontal_line = "â”€" * (box_width - 2)
        self.logger.info(f"â”Œ{horizontal_line}â”")
        
        # ì œëª©
        title_padded = f"{icon} {title}".center(box_width - 2)
        self.logger.info(f"â”‚{title_padded}â”‚")
        
        if data:
            self.logger.info(f"â”œ{horizontal_line}â”¤")
            
            # ë°ì´í„° ì¶œë ¥
            for key, value in data.items():
                content = f" {key}: {value}"
                padding = " " * (box_width - len(content) - 1)
                self.logger.info(f"â”‚{content}{padding}â”‚")
        
        self.logger.info(f"â””{horizontal_line}â”˜")
    
    def redis_data_box(self, operation: str, query: str, data: Dict):
        """Redis ë°ì´í„° ì •í˜•í™” ë°•ìŠ¤"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        box_data = {
            "Operation": operation,
            "Query": f'"{query_preview}"',
            "Similarity": f"{data.get('similarity_score', 0):.1%}" if data.get('similarity_score') else "N/A",
            "Search Count": f"{data.get('current_count', 0)} times",
            "TTL": data.get('ttl', '1 hour'),
            "Cached At": data.get('cached_at', 'N/A'),
            "Duration": f"{data.get('duration', 0):.3f}s" if data.get('duration') else "N/A"
        }
        
        # ë¶ˆí•„ìš”í•œ N/A ì œê±°
        filtered_data = {k: v for k, v in box_data.items() if v != "N/A"}
        
        self.structured_log_box(f"REDIS - {operation}", filtered_data, "REDIS")
    
    def mysql_data_box(self, operation: str, query: str, data: Dict):
        """MySQL ë°ì´í„° ì •í˜•í™” ë°•ìŠ¤"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        box_data = {
            "Operation": operation,
            "Query": f'"{query_preview}"' if query else "N/A",
            "Search Count": f"{data.get('search_count', 0)} times",
            "Category": data.get('category', 'N/A'),
            "Similarity": f"{data.get('similarity', 0):.1%}" if data.get('similarity') else "N/A",
            "Total Questions": data.get('total_questions', 'N/A'),
            "Total Searches": data.get('total_searches', 'N/A'),
            "Deleted Records": data.get('deleted_count', 'N/A')
        }
        
        # ë¶ˆí•„ìš”í•œ N/A ì œê±°
        filtered_data = {k: v for k, v in box_data.items() if v != "N/A"}
        
        self.structured_log_box(f"MYSQL - {operation}", filtered_data, "MYSQL")
    
    def system_summary_box(self, query: str, summary_data: Dict):
        """ì‹œìŠ¤í…œ ì²˜ë¦¬ ìš”ì•½ ë°•ìŠ¤"""
        query_preview = query[:30] + "..." if len(query) > 30 else query
        
        box_data = {
            "Query": f'"{query_preview}"',
            "Request Count": f"#{summary_data.get('request_count', 1)}",
            "Max Similarity": f"{summary_data.get('max_similarity', 0):.1%}",
            "Response Type": summary_data.get('response_type', 'Unknown'),
            "Cached": "âœ… Yes" if summary_data.get('cached') else "âŒ No",
            "Popular Saved": "âœ… Yes" if summary_data.get('popular_saved') else "âŒ No",
            "Total Duration": f"{summary_data.get('total_duration', 0):.3f}s",
            "LLM Duration": f"{summary_data.get('llm_duration', 0):.3f}s" if summary_data.get('llm_duration') else "N/A"
        }
        
        # ë¶ˆí•„ìš”í•œ N/A ì œê±°
        filtered_data = {k: v for k, v in box_data.items() if v != "N/A"}
        
        self.structured_log_box("PROCESSING SUMMARY", filtered_data, "SUCCESS")

# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_enhanced_logger = None

def get_enhanced_logger() -> EnhancedLogger:
    """ì „ì—­ í–¥ìƒëœ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _enhanced_logger
    if _enhanced_logger is None:
        _enhanced_logger = EnhancedLogger()
    return _enhanced_logger