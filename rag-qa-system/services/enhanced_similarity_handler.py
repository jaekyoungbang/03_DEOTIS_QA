"""
í–¥ìƒëœ ìœ ì‚¬ë„ ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬ê¸°
- Redis ìºì‹œ í†µí•©
- MySQL ì¸ê¸°ì§ˆë¬¸ ê´€ë¦¬
- 50% ë¯¸ë§Œ ì‹œ ì¸ê¸°ì§ˆë¬¸ ë²„íŠ¼ í‘œì‹œ
"""

from typing import List, Dict, Tuple, Optional, Any
from langchain.schema import Document
from .redis_cache_manager import RedisCacheManager  
from .popular_question_manager import PopularQuestionManager
from .application_initializer import get_application_initializer
from .enhanced_logger import get_enhanced_logger
import logging
import time

logger = logging.getLogger(__name__)
enhanced_logger = get_enhanced_logger()

class EnhancedSimilarityHandler:
    """í–¥ìƒëœ ìœ ì‚¬ë„ ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬"""
    
    def __init__(self, threshold: float = 0.75):
        """ì´ˆê¸°í™”"""
        self.threshold = threshold
        self.personalized_threshold = 0.65  # ê°œì¸í™” ì¿¼ë¦¬ìš© ì„ê³„ê°’
        self.low_similarity_threshold = 0.50  # ì¸ê¸°ì§ˆë¬¸ í‘œì‹œ ê¸°ì¤€
        
        # ìºì‹œì™€ ì¸ê¸°ì§ˆë¬¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        initializer = get_application_initializer()
        self.redis_manager, self.popular_manager = initializer.get_managers()
        
        # ê¸°ë³¸ ì¶”ì²œ ì§ˆë¬¸ (Redis/MySQL ì—°ê²° ì‹¤íŒ¨ì‹œ ì‚¬ìš©)
        self.fallback_questions = {
            "card": [
                "BCì¹´ë“œ ë°œê¸‰ ì ˆì°¨ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤",
                "BCì¹´ë“œ íšŒì›ì€í–‰ë³„ ì•ˆë‚´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”", 
                "BCì¹´ë“œ ì‹ ì²­ ìê²© ì¡°ê±´ì´ ë¬´ì—‡ì¸ê°€ìš”?"
            ],
            "personal": [
                "ê¹€ëª…ì • ê³ ê°ì˜ ë³´ìœ  ì¹´ë“œ í˜„í™©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                "ê¹€ëª…ì • ê³ ê°ì—ê²Œ ì¶”ì²œí•˜ëŠ” ì¹´ë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ê¹€ëª…ì • ê³ ê°ì˜ ì¹´ë“œ ì´ìš© ë‚´ì—­ì„ í™•ì¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤"
            ],
            "general": [
                "BCì¹´ë“œë€ ë¬´ì—‡ì¸ê°€ìš”?",
                "BCì¹´ë“œì˜ ì£¼ìš” í˜œíƒì„ ì•Œë ¤ì£¼ì„¸ìš”",
                "BCì¹´ë“œ ê³ ê°ì„¼í„° ì—°ë½ì²˜ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤"
            ]
        }
    
    def process_question(
        self, 
        question: str, 
        vectorstore_search_func,
        chunking_type: str = "basic"
    ) -> Dict:
        """ì§ˆë¬¸ ì „ì²´ ì²˜ë¦¬ (ìºì‹œ í™•ì¸ â†’ ê²€ìƒ‰ â†’ ê²°ê³¼ ì²˜ë¦¬)"""
        
        start_time = time.time()
        enhanced_logger.question_flow(question, "START", {})
        
        # 1. Redis ìºì‹œ í™•ì¸
        enhanced_logger.question_flow(question, "CACHE_CHECK", {})
        cached_result = self._check_cache(question)
        
        if cached_result:
            duration = time.time() - start_time
            enhanced_logger.question_flow(question, "CACHE_CHECK", {"hit": True})
            enhanced_logger.search_operation(
                question, cached_result['max_similarity'], 
                "Redis Cache", cached=True, duration=duration
            )
            enhanced_logger.question_flow(question, "END", {"cached": True})
            return cached_result
        
        enhanced_logger.question_flow(question, "CACHE_CHECK", {"hit": False})
        
        # 2. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        search_start = time.time()
        search_results = vectorstore_search_func(question)
        search_duration = time.time() - search_start
        
        max_similarity = search_results[0][1] if search_results else 0.0
        enhanced_logger.question_flow(question, "VECTOR_SEARCH", {"similarity": max_similarity})
        enhanced_logger.search_operation(
            question, max_similarity, chunking_type, 
            cached=False, duration=search_duration
        )
        
        # 3. ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        processed_result = self.process_search_results(
            search_results, question, chunking_type
        )
        
        enhanced_logger.question_flow(question, "RESPONSE_TYPE", {
            "type": processed_result["response_type"],
            "threshold_met": processed_result["threshold_met"],
            "show_popular_buttons": processed_result.get("show_popular_buttons", False)
        })
        
        # 4. ìºì‹± ë° ì¸ê¸°ì§ˆë¬¸ ì²˜ë¦¬
        caching_info = self._handle_caching_and_popularity(question, processed_result)
        
        total_duration = time.time() - start_time
        enhanced_logger.question_flow(question, "END", {
            "cached": caching_info.get("cached", False),
            "popular_saved": caching_info.get("popular_saved", False)
        })
        
        enhanced_logger.performance_metrics("QUESTION_PROCESSING", {
            "total_time": total_duration,
            "search_time": search_duration,
            "cache_check_time": search_start - start_time,
            "processing_time": total_duration - search_duration - (search_start - start_time),
            "similarity_score": max_similarity
        })
        
        return processed_result
    
    def _check_cache(self, question: str) -> Optional[Dict]:
        """Redis ìºì‹œ í™•ì¸"""
        if not self.redis_manager or not self.redis_manager.is_connected():
            return None
        
        try:
            cached_data = self.redis_manager.get_cached_result(question)
            if cached_data:
                # ìºì‹œëœ ë°ì´í„°ë¥¼ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                return {
                    "response_type": "cached",
                    "should_answer": True,
                    "context": cached_data['result'].get('context', ''),
                    "similarity_info": cached_data['result'].get('similarity_info', []),
                    "max_similarity": cached_data['similarity_score'],
                    "threshold_met": True,
                    "cached": True,
                    "cache_timestamp": cached_data['cached_at']
                }
        except Exception as e:
            logger.error(f"ìºì‹œ í™•ì¸ ì˜¤ë¥˜: {e}")
        
        return None
    
    def process_search_results(
        self, 
        search_results: List[Tuple[Document, float]], 
        question: str,
        chunking_type: str = "basic"
    ) -> Dict:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬"""
        
        # ìµœê³  ìœ ì‚¬ë„ í™•ì¸
        max_similarity = search_results[0][1] if search_results else 0.0
        
        # ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = self._categorize_question(question)
        
        # ê°œì¸í™” ì¿¼ë¦¬ì¸ì§€ í™•ì¸í•˜ì—¬ ì„ê³„ê°’ ì¡°ì •
        is_personalized = category == "personal" or any(name in question for name in ["ê¹€ëª…ì •", "ì´ì˜í¬", "ë°•ì² ìˆ˜"])
        effective_threshold = self.personalized_threshold if is_personalized else self.threshold
        
        logger.info(f"ğŸ¯ [EnhancedHandler] ì¹´í…Œê³ ë¦¬: {category}, ê°œì¸í™”: {is_personalized}")
        logger.info(f"ğŸ“Š [EnhancedHandler] ìµœê³ ìœ ì‚¬ë„: {max_similarity:.2%}, ì„ê³„ê°’: {effective_threshold:.2%}")
        
        # ìœ ì‚¬ë„ ì„ê³„ê°’ ì²´í¬
        if max_similarity >= effective_threshold:
            # ì •ìƒ ì‘ë‹µ ì²˜ë¦¬ (70% ì´ìƒì´ë©´ ìºì‹œ ëŒ€ìƒ)
            result = {
                "response_type": "normal",
                "should_answer": True,
                "context": self._build_context(search_results, chunking_type),
                "similarity_info": self._format_similarity_info(search_results),
                "max_similarity": max_similarity,
                "threshold_met": True,
                "cached": False
            }
            return result
            
        elif max_similarity >= self.low_similarity_threshold:
            # ì¤‘ê°„ ìœ ì‚¬ë„ - ì¼ë°˜ ì¶”ì²œ ì§ˆë¬¸
            return {
                "response_type": "medium_similarity",
                "should_answer": False,
                "suggested_questions": self._get_suggested_questions(category, question),
                "similarity_info": self._format_similarity_info(search_results),
                "max_similarity": max_similarity,
                "threshold_met": False,
                "message": f"ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ìœ ì‚¬ë„: {max_similarity*100:.1f}%)."
            }
        else:
            # ë‚®ì€ ìœ ì‚¬ë„ (50% ë¯¸ë§Œ) - ì¸ê¸°ì§ˆë¬¸ ë²„íŠ¼ í‘œì‹œ
            popular_questions = self._get_popular_questions()
            return {
                "response_type": "low_similarity", 
                "should_answer": False,
                "suggested_questions": self._get_suggested_questions(category, question),
                "popular_questions": popular_questions,  # ë²„íŠ¼ìš© ì¸ê¸°ì§ˆë¬¸
                "similarity_info": self._format_similarity_info(search_results),
                "max_similarity": max_similarity,
                "threshold_met": False,
                "message": f"ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ìœ ì‚¬ë„: {max_similarity*100:.1f}%).",
                "show_popular_buttons": True
            }
    
    def _handle_caching_and_popularity(self, question: str, result: Dict) -> Dict:
        """ìºì‹± ë° ì¸ê¸°ì§ˆë¬¸ ì²˜ë¦¬"""
        max_similarity = result.get('max_similarity', 0.0)
        info = {"cached": False, "popular_saved": False}
        
        # 1. 70% ì´ìƒì´ë©´ Redis ìºì‹±
        if max_similarity >= 0.70 and self.redis_manager:
            try:
                cache_success = self.redis_manager.cache_result(
                    question, result, max_similarity
                )
                info["cached"] = cache_success
            except Exception as e:
                enhanced_logger.redis_operation("CACHE_ERROR", question, error=str(e))
        
        # 2. ê²€ìƒ‰ íšŸìˆ˜ í™•ì¸ í›„ 5íšŒ ì´ìƒì´ë©´ MySQL ì €ì¥
        if self.redis_manager and self.popular_manager:
            try:
                search_count = self.redis_manager.get_search_count(question)
                if search_count >= 5:
                    category = self._categorize_question(question)
                    popular_success = self.popular_manager.add_popular_question(
                        question, search_count, max_similarity, category
                    )
                    info["popular_saved"] = popular_success
            except Exception as e:
                enhanced_logger.mysql_operation("POPULAR_ERROR", question, error=str(e))
        
        return info
    
    def _get_popular_questions(self) -> List[str]:
        """50% ë¯¸ë§Œ ì‹œ í‘œì‹œí•  ì¸ê¸°ì§ˆë¬¸ 3ê°œ (ë²„íŠ¼ìš©)"""
        if self.popular_manager and self.popular_manager.is_connected():
            try:
                return self.popular_manager.get_top_3_popular_questions()
            except Exception as e:
                logger.error(f"ì¸ê¸°ì§ˆë¬¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        
        # í´ë°±: ê¸°ë³¸ ì¶”ì²œ ì§ˆë¬¸
        return self.fallback_questions["card"][:3]
    
    def _categorize_question(self, question: str) -> str:
        """ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if any(name in question for name in ["ê¹€ëª…ì •", "ê¹€ì² ìˆ˜", "ë°•ì˜í¬"]):
            return "personal"
        elif any(keyword in question for keyword in ["ì¹´ë“œ", "ë°œê¸‰", "ì‹ ì²­", "BCì¹´ë“œ"]):
            return "card"
        else:
            return "general"
    
    def _build_context(self, search_results: List[Tuple[Document, float]], chunking_type: str) -> str:
        """ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = ""
        for doc, score in search_results[:3]:  # Top 3
            content = doc.page_content
            
            # ì²­í‚¹ íƒ€ì…ë³„ ì²˜ë¦¬
            if chunking_type == "custom" and "![" in content:
                # ì´ë¯¸ì§€ í¬í•¨ëœ ì»¨í…ìŠ¤íŠ¸
                context += f"[ìœ ì‚¬ë„: {score:.1%}] {content}\\n\\n"
            else:
                # í…ìŠ¤íŠ¸ë§Œ
                context += f"[ìœ ì‚¬ë„: {score:.1%}] {content}\\n\\n"
        
        return context.strip()
    
    def _format_similarity_info(self, search_results: List[Tuple[Document, float]]) -> List[Dict]:
        """ìœ ì‚¬ë„ ì •ë³´ í¬ë§·íŒ…"""
        similarity_info = []
        for i, (doc, score) in enumerate(search_results[:3], 1):
            info = {
                "rank": i,
                "score": f"{score:.1%}",
                "score_raw": score,
                "source": doc.metadata.get("source", "unknown"),
                "preview": doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
            }
            similarity_info.append(info)
        
        return similarity_info
    
    def _get_suggested_questions(self, category: str, original_question: str) -> List[str]:
        """ì¶”ì²œ ì§ˆë¬¸ ìƒì„±"""
        base_questions = self.fallback_questions.get(category, self.fallback_questions["general"])
        
        # ì›ë³¸ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ì¶”ì²œ ì§ˆë¬¸ ìš°ì„ ìˆœìœ„ ì¡°ì •
        keywords = self._extract_keywords(original_question)
        scored_questions = []
        
        for question in base_questions:
            score = sum(1 for keyword in keywords if keyword in question)
            scored_questions.append((score, question))
        
        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_questions.sort(key=lambda x: x[0], reverse=True)
        
        return [q[1] for q in scored_questions[:5]]  # Top 5 ì¶”ì²œ
    
    def _extract_keywords(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        important_words = ["ì¹´ë“œ", "ë°œê¸‰", "ì‹ ì²­", "BC", "ì•ˆë‚´", "ì ˆì°¨", "ì„œë¥˜", "ìê²©", "í˜œíƒ", "ì—°íšŒë¹„"]
        
        for word in important_words:
            if word in question:
                keywords.append(word)
        
        return keywords
    
    def format_response_with_threshold(self, result: Dict) -> str:
        """ì„ê³„ê°’ ê¸°ë°˜ ì‘ë‹µ í¬ë§·íŒ…"""
        if result["threshold_met"]:
            # ì •ìƒ ì‘ë‹µ
            return result.get("answer", "")
        elif result.get("show_popular_buttons", False):
            # 50% ë¯¸ë§Œ - ì¸ê¸°ì§ˆë¬¸ ë²„íŠ¼ í‘œì‹œ
            response = f"{result['message']}\\n\\n"
            response += "ë‹¤ìŒ ì¤‘ì—ì„œ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì„ íƒí•´ì£¼ì„¸ìš”:\\n\\n"
            
            for i, question in enumerate(result.get('popular_questions', []), 1):
                response += f"ğŸ”˜ {question}\\n"
            
            return response
        else:
            # ì¤‘ê°„ ìœ ì‚¬ë„ - ì¼ë°˜ ì¶”ì²œì§ˆë¬¸
            response = f"{result['message']}\\n\\n"
            response += "ì•„ë˜ì™€ ê°™ì€ ì§ˆë¬¸ë“¤ì€ ì–´ë– ì‹ ê°€ìš”?\\n\\n"
            
            for i, question in enumerate(result['suggested_questions'], 1):
                response += f"{i}. {question}\\n"
            
            return response