from typing import List, Dict, Tuple, Any, Optional
import numpy as np
from services.enhanced_rag_chain import EnhancedRAGChain
from models.dual_llm import DualLLMManager
from config import Config
import re


class EnhancedRAGChainWithImages(EnhancedRAGChain):
    """ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬ê°€ ì¶”ê°€ëœ ê°œì„ ëœ RAG ì²´ì¸"""
    
    def __init__(self, vectorstore):
        super().__init__(vectorstore)
        self.image_pattern = re.compile(r'!\[.*?\]\((.*?)\)')
        
    def _extract_images_from_documents(self, documents: List) -> List[Dict]:
        """ë¬¸ì„œì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ"""
        all_images = []
        seen_paths = set()  # ì¤‘ë³µ ì œê±°
        
        for doc in documents:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
            if hasattr(doc, 'metadata'):
                images_in_metadata = doc.metadata.get('images', [])
                for img in images_in_metadata:
                    if img['path'] not in seen_paths:
                        seen_paths.add(img['path'])
                        all_images.append({
                            'path': img['path'],
                            'source': doc.metadata.get('filename', 'unknown'),
                            'section': doc.metadata.get('section', ''),
                            'type': 'metadata'
                        })
            
            # ì½˜í…ì¸ ì—ì„œë„ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
            if hasattr(doc, 'page_content'):
                for match in self.image_pattern.finditer(doc.page_content):
                    path = match.group(1)
                    if path not in seen_paths:
                        seen_paths.add(path)
                        all_images.append({
                            'path': path,
                            'source': doc.metadata.get('filename', 'unknown') if hasattr(doc, 'metadata') else 'unknown',
                            'section': doc.metadata.get('section', '') if hasattr(doc, 'metadata') else '',
                            'type': 'content'
                        })
        
        return all_images
    
    def _create_context_with_images(self, documents: List, images: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ì •ë³´ë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context_parts = []
        
        # ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
        for i, doc in enumerate(documents):
            content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            
            context_parts.append(f"[ë¬¸ì„œ {i+1}]")
            if metadata.get('section'):
                context_parts.append(f"ì„¹ì…˜: {metadata['section']}")
            context_parts.append(content)
            context_parts.append("")
        
        # ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
        if images:
            context_parts.append("\n[ê´€ë ¨ ì´ë¯¸ì§€ ì •ë³´]")
            for img in images:
                context_parts.append(f"- ì´ë¯¸ì§€ ê²½ë¡œ: {img['path']}")
                if img['section']:
                    context_parts.append(f"  ì„¹ì…˜: {img['section']}")
                if img['source']:
                    context_parts.append(f"  ì¶œì²˜: {img['source']}")
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    def process_query(self, query: str, top_k: int = 3, chunking_type: str = None) -> Dict:
        """ì§ˆì˜ ì²˜ë¦¬ - ì´ë¯¸ì§€ ì •ë³´ í¬í•¨"""
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        results = self._search_documents(query, top_k, chunking_type)
        
        if not results:
            return {
                'type': 'error',
                'message': 'ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        # 2. ë¬¸ì„œì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
        documents = [doc for doc, _ in results[:top_k]]
        images = self._extract_images_from_documents(documents)
        
        # 3. ì´ë¯¸ì§€ í¬í•¨ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self._create_context_with_images(documents, images)
        
        # 4. LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if chunking_type == 'custom':
            # s3-chunking ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸
            prompt_template = """ë‹¹ì‹ ì€ BCì¹´ë“œ ê³ ê° ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë¬¸ì„œì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ì„œì— í…Œì´ë¸”ì´ë‚˜ í‘œê°€ ìˆëŠ” ê²½ìš°, êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œí•´ì£¼ì„¸ìš”.
ì´ë¯¸ì§€ê°€ ê´€ë ¨ëœ ê²½ìš°, ì´ë¯¸ì§€ ì •ë³´ë„ í•¨ê»˜ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
        else:
            # ê¸°ë³¸ ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸
            prompt_template = """ë‹¹ì‹ ì€ BCì¹´ë“œ ê³ ê° ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
        
        # 5. LLM ì‘ë‹µ ìƒì„±
        try:
            if self.use_benchmarking:
                # ë²¤ì¹˜ë§ˆí‚¹ ëª¨ë“œ
                response = self._generate_benchmarking_response(query, context, prompt_template, images)
            else:
                # ì¼ë°˜ ëª¨ë“œ
                response = self._generate_normal_response(query, context, prompt_template, images)
            
            # ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
            if images:
                response['images'] = images
                response['has_images'] = True
            
            return response
            
        except Exception as e:
            print(f"[ENHANCED_RAG_IMAGES] ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'type': 'error',
                'message': f'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }
    
    def _generate_normal_response(self, query: str, context: str, prompt_template: str, images: List[Dict]) -> Dict:
        """ì¼ë°˜ ëª¨ë“œ ì‘ë‹µ ìƒì„±"""
        try:
            # í˜„ì¬ í™œì„± LLM í™•ì¸
            current_llm_type = Config.LLM_TYPE
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = prompt_template.format(context=context, query=query)
            
            # LLM ì‘ë‹µ ìƒì„±
            if current_llm_type == "local":
                llm_response = self.dual_llm.local_llm.invoke(prompt)
                answer = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
                llm_name = "ì‚¬ë‚´ì„œë²„ vLLM"
            else:
                llm_response = self.dual_llm.openai_llm.invoke(prompt)
                answer = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
                llm_name = "ChatGPT"
            
            # ì´ë¯¸ì§€ ì°¸ì¡° ì¶”ê°€ (ë‹µë³€ì— ì´ë¯¸ì§€ ì–¸ê¸‰ì´ ìˆì„ ê²½ìš°)
            if images and "ì´ë¯¸ì§€" in answer:
                answer += "\n\nğŸ“· ê´€ë ¨ ì´ë¯¸ì§€ê°€ ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            
            return {
                'type': 'normal',
                'answer': answer,
                'llm_used': llm_name,
                'context_length': len(context),
                'images_found': len(images)
            }
            
        except Exception as e:
            print(f"[ENHANCED_RAG_IMAGES] ì¼ë°˜ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            raise
    
    def _generate_benchmarking_response(self, query: str, context: str, prompt_template: str, images: List[Dict]) -> Dict:
        """ë²¤ì¹˜ë§ˆí‚¹ ëª¨ë“œ ì‘ë‹µ ìƒì„±"""
        try:
            prompt = prompt_template.format(context=context, query=query)
            
            # ë‘ LLMì—ì„œ ì‘ë‹µ ìƒì„±
            benchmark_result = self.benchmarker.benchmark_query(
                query=query,
                context=context,
                prompt=prompt
            )
            
            # ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€
            if images:
                benchmark_result['images_found'] = len(images)
                
                # ê° LLM ì‘ë‹µì— ì´ë¯¸ì§€ ì°¸ì¡° ì¶”ê°€
                for llm_type in ['local_llm', 'openai_llm']:
                    if llm_type in benchmark_result and "ì´ë¯¸ì§€" in benchmark_result[llm_type].get('answer', ''):
                        benchmark_result[llm_type]['answer'] += "\n\nğŸ“· ê´€ë ¨ ì´ë¯¸ì§€ê°€ ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            
            return benchmark_result
            
        except Exception as e:
            print(f"[ENHANCED_RAG_IMAGES] ë²¤ì¹˜ë§ˆí‚¹ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            raise


def create_enhanced_rag_chain_with_images(vectorstore):
    """ì´ë¯¸ì§€ ì²˜ë¦¬ê°€ í¬í•¨ëœ ê°œì„ ëœ RAG ì²´ì¸ ìƒì„±"""
    return EnhancedRAGChainWithImages(vectorstore)