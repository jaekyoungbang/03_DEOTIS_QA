# RAG QA ì‹œìŠ¤í…œ ê¸°ìˆ  ë°œí‘œ ìë£Œ

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#2-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ê¸°ìˆ  ìŠ¤íƒ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬](#3-ê¸°ìˆ -ìŠ¤íƒ-ë°-ë¼ì´ë¸ŒëŸ¬ë¦¬)
4. [ë¬¸ì„œ ë¡œë”© ë° ì²­í‚¹ ì „ëµ](#4-ë¬¸ì„œ-ë¡œë”©-ë°-ì²­í‚¹-ì „ëµ)
5. [ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥](#5-ì„ë² ë”©-ë°-ë²¡í„°-db-ì €ì¥)
6. [ê²€ìƒ‰ ë° ìœ ì‚¬ë„ ì¸¡ì •](#6-ê²€ìƒ‰-ë°-ìœ ì‚¬ë„-ì¸¡ì •)
7. [4ê°€ì§€ ë²¤ì¹˜ë§ˆí‚¹ ëª¨ë“œ](#7-4ê°€ì§€-ë²¤ì¹˜ë§ˆí‚¹-ëª¨ë“œ)
8. [vLLM + kanana8b ì„ íƒ ì´ìœ ](#8-vllm--kanana8b-ì„ íƒ-ì´ìœ )
9. [ì„±ëŠ¥ ë° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°](#9-ì„±ëŠ¥-ë°-ì‹¤ì‹œê°„-ìŠ¤íŠ¸ë¦¬ë°)
10. [ê²°ê³¼ ë° í–¥í›„ ê³„íš](#10-ê²°ê³¼-ë°-í–¥í›„-ê³„íš)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ
- BCì¹´ë“œ ì—…ë¬´ ì§€ì‹ì„ í™œìš©í•œ ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•
- ë‹¤ì–‘í•œ ì²­í‚¹ ì „ëµê³¼ LLM ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
- ì‹¤ì‹œê°„ ë©€í‹° ë²¤ì¹˜ë§ˆí‚¹ì„ í†µí•œ ìµœì  êµ¬ì„± íƒìƒ‰

### ğŸŒŸ ì£¼ìš” íŠ¹ì§•
- **ë“€ì–¼ ì²­í‚¹ ì „ëµ**: s3 ê¸°ë³¸ vs s3-chunking ì»¤ìŠ¤í…€
- **ë©€í‹° LLM ì§€ì›**: ChatGPT vs ë¡œì»¬ kanana8b ëª¨ë¸
- **ì‹¤ì‹œê°„ ë²¤ì¹˜ë§ˆí‚¹**: 4ê°€ì§€ ì¡°í•© ë™ì‹œ ì„±ëŠ¥ ë¹„êµ
- **í•˜ì´ë¸Œë¦¬ë“œ ìºì‹±**: Redis + SQLite 2ë‹¨ê³„ ìºì‹œ ì‹œìŠ¤í…œ

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    A[ì‚¬ìš©ì ì›¹ ì¸í„°í˜ì´ìŠ¤] --> B[Flask API ì„œë²„]
    B --> C[RAG Chain Engine]
    
    C --> D[ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ]
    C --> E[ë“€ì–¼ LLM ì‹œìŠ¤í…œ]
    
    D --> F[ChromaDB<br/>ê¸°ë³¸ ì²­í‚¹]
    D --> G[ChromaDB<br/>ì»¤ìŠ¤í…€ ì²­í‚¹]
    
    E --> H[ChatGPT API<br/>GPT-4o-mini]
    E --> I[vLLM ì„œë²„<br/>kanana8b]
    
    J[ë¬¸ì„œ ë¡œë”] --> K[S3 í´ë”<br/>ê¸°ë³¸ ì²­í‚¹]
    J --> L[S3-chunking í´ë”<br/>ì»¤ìŠ¤í…€ ì²­í‚¹]
    
    K --> F
    L --> G
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#ffebee
```

### ğŸ—ï¸ ì•„í‚¤í…ì²˜ êµ¬ì„±ìš”ì†Œ

| ê³„ì¸µ | êµ¬ì„±ìš”ì†Œ | ì—­í•  |
|------|----------|------|
| **í”„ë¡ íŠ¸ì—”ë“œ** | Flask Web App + Swagger | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° API ë¬¸ì„œ |
| **ë°±ì—”ë“œ** | LangChain RAG Engine | ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬ ë¡œì§ |
| **ë²¡í„° DB** | ChromaDB (Dual Collections) | ë¬¸ì„œ ì„ë² ë”© ì €ì¥ ë° ê²€ìƒ‰ |
| **ìºì‹œ** | Redis + SQLite | ì‘ë‹µ ì†ë„ ìµœì í™” |
| **LLM** | ChatGPT + vLLM/kanana8b | ë‹µë³€ ìƒì„± ì—”ì§„ |

---

## 3. ê¸°ìˆ  ìŠ¤íƒ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

### ğŸ› ï¸ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ

#### **ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬**
```python
# Flask ê¸°ë°˜ API ì„œë²„
from flask import Flask
from flask_restx import Api, Resource  # Swagger ìë™ ìƒì„±
from flask_cors import CORS           # CORS ì§€ì›
```

#### **LangChain ìƒíƒœê³„**
```python
# ë¬¸ì„œ ì²˜ë¦¬ ë° RAG êµ¬í˜„
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains import RetrievalQA
```

#### **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**
```python
# ChromaDB - ê³ ì„±ëŠ¥ ì„ë² ë”© ê²€ìƒ‰
import chromadb
from chromadb.config import Settings

# ë²¡í„° ì €ì¥ ì„¤ì •
CHROMA_SETTINGS = Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory="./chromadb",
    anonymized_telemetry=False
)
```

#### **ì„ë² ë”© ëª¨ë¸**
- **Primary**: BGE-M3 (1024ì°¨ì›) - í•œêµ­ì–´ ìµœì í™”
- **Fallback**: OpenAI text-embedding-3-small (1536ì°¨ì›)

### ğŸ“¦ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „
| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë²„ì „ | ìš©ë„ |
|------------|------|------|
| `langchain-community` | latest | ë¬¸ì„œ ë¡œë”, ë²¡í„° ìŠ¤í† ì–´ |
| `langchain-openai` | latest | OpenAI API í†µí•© |
| `chromadb` | latest | ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ |
| `flask-restx` | latest | REST API + Swagger |
| `python-docx` | latest | DOCX íŒŒì¼ ì²˜ë¦¬ |
| `numpy` | latest | ìˆ˜ì¹˜ ì—°ì‚° |

---

## 4. ë¬¸ì„œ ë¡œë”© ë° ì²­í‚¹ ì „ëµ

### ğŸ“ ë“€ì–¼ í´ë” êµ¬ì¡°
```
D:\99_DEOTIS_QA_SYSTEM\03_DEOTIS_QA\
â”œâ”€â”€ s3/                     # ê¸°ë³¸ ì²­í‚¹ ì „ëµ
â”‚   â”œâ”€â”€ BCì¹´ë“œ(ì‹ ìš©ì¹´ë“œ ì—…ë¬´ì²˜ë¦¬ ì•ˆë‚´).docx
â”‚   â””â”€â”€ BCì¹´ë“œ(ì¹´ë“œì´ìš©ì•ˆë‚´).docx
â””â”€â”€ s3-chunking/            # ì»¤ìŠ¤í…€ ì²­í‚¹ ì „ëµ
    â”œâ”€â”€ BCì¹´ë“œ(ì‹ ìš©ì¹´ë“œ ì—…ë¬´ì²˜ë¦¬ ì•ˆë‚´)_delimited.docx
    â””â”€â”€ BCì¹´ë“œ(ì¹´ë“œì´ìš©ì•ˆë‚´).docx
```

### ğŸ”„ ì²­í‚¹ ì „ëµ ë¹„êµ

#### **S3 ê¸°ë³¸ ì²­í‚¹ (BasicChunkingStrategy)**
```python
class BasicChunkingStrategy:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,           # ì²­í¬ í¬ê¸°
            chunk_overlap=200,         # ê²¹ì¹¨ í¬ê¸°
            separators=["\n\n\n", "\n\n", "\n", ". ", " ", ""],
            length_function=len
        )
```

**íŠ¹ì§•:**
- ğŸ“ **ì²­í¬ í¬ê¸°**: 1000ì + 200ì ê²¹ì¹¨
- ğŸ“ **ë¶„ë¦¬ì**: ë¬¸ë‹¨, ë¬¸ì¥, ë‹¨ì–´ ìˆœì„œë¡œ ë¶„í• 
- ğŸ¯ **ì ìš© ëŒ€ìƒ**: ì¼ë°˜ ë¬¸ì„œ êµ¬ì¡°

#### **S3-chunking ì»¤ìŠ¤í…€ ì²­í‚¹ (CustomDelimiterChunkingStrategy)**
```python
class CustomDelimiterChunkingStrategy:
    def __init__(self):
        self.delimiter = "/$$/"      # ì»¤ìŠ¤í…€ êµ¬ë¶„ì
        self.min_chunk_length = 50   # ìµœì†Œ ì²­í¬ ê¸¸ì´
        self.title_filter_enabled = True  # ì œëª© í•„í„°ë§
```

**íŠ¹ì§•:**
- ğŸ¯ **êµ¬ë¶„ì ê¸°ë°˜**: `/$/` ë§ˆì»¤ë¡œ ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• 
- ğŸ” **ì œëª© í•„í„°ë§**: í—¤ë” ì „ìš© ì²­í¬ ì œê±°
- ğŸ“Š **ì„¹ì…˜ ì¸ì‹**: "10)", "A-1.", "[ì œëª©]" íŒ¨í„´ ì¸ì‹
- ğŸš« **ì¤‘ë³µ ì œê±°**: ì „ì—­ ë° ì»¬ë ‰ì…˜ë³„ ì¤‘ë³µ ì œê±°

### ğŸ“ˆ ì²­í‚¹ ê²°ê³¼ í†µê³„
| ì „ëµ | ë¬¸ì„œ ìˆ˜ | ìƒì„± ì²­í¬ | ê³ ìœ  ì²­í¬ | ì¤‘ë³µ ì œê±°ìœ¨ |
|------|---------|-----------|-----------|-------------|
| **ê¸°ë³¸ ì²­í‚¹** | 2ê°œ | 98ê°œ | 98ê°œ | 0% |
| **ì»¤ìŠ¤í…€ ì²­í‚¹** | 2ê°œ | 135ê°œ | 135ê°œ | 37% |
| **ì „ì²´** | 4ê°œ | 233ê°œ | 233ê°œ | 15% |

---

## 5. ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥

### ğŸ§  ì„ë² ë”© ëª¨ë¸ ì„ íƒ

#### **Primary: BGE-M3 (í•œêµ­ì–´ ìµœì í™”)**
```python
class EmbeddingManager:
    def __init__(self):
        self.bge_embeddings = OllamaEmbeddings(
            base_url="http://192.168.0.224:11434",
            model="bge-m3"
        )
        # 1024ì°¨ì›, í•œêµ­ì–´ íŠ¹í™”
```

**BGE-M3 ì„ íƒ ì´ìœ :**
- ğŸ‡°ğŸ‡· **í•œêµ­ì–´ ìµœì í™”**: BCì¹´ë“œ ì—…ë¬´ ë¬¸ì„œì— íŠ¹í™”
- âš¡ **ì„±ëŠ¥**: 1024ì°¨ì›ìœ¼ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬
- ğŸ”’ **ë¡œì»¬ ë°°í¬**: ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ë³´ì¥

#### **Fallback: OpenAI Embedding**
```python
self.openai_embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    dimensions=1536
)
```

### ğŸ—„ï¸ ë“€ì–¼ ë²¡í„° ìŠ¤í† ì–´ ì•„í‚¤í…ì²˜

```python
class DualVectorStoreManager:
    def __init__(self, embeddings):
        self.basic_vectorstore = Chroma(
            collection_name="basic_chunks",
            embedding_function=embeddings,
            persist_directory="./chromadb"
        )
        self.custom_vectorstore = Chroma(
            collection_name="custom_chunks", 
            embedding_function=embeddings,
            persist_directory="./chromadb"
        )
```

### ğŸ’¾ ì €ì¥ í”„ë¡œì„¸ìŠ¤

1. **ë¬¸ì„œ ë¡œë”©** â†’ s3, s3-chunking í´ë”ì—ì„œ ë¬¸ì„œ ì½ê¸°
2. **ì²­í‚¹ ì ìš©** â†’ í´ë”ë³„ ì²­í‚¹ ì „ëµ ì„ íƒ
3. **ì„ë² ë”© ìƒì„±** â†’ BGE-M3ìœ¼ë¡œ 1024ì°¨ì› ë²¡í„° ë³€í™˜
4. **ë©”íƒ€ë°ì´í„° ì¶”ê°€** â†’ ì²­í‚¹ íƒ€ì…, ì†ŒìŠ¤ ì •ë³´ íƒœê¹…
5. **ë²¡í„° ì €ì¥** â†’ ChromaDB ë³„ë„ ì»¬ë ‰ì…˜ì— ì €ì¥

### ğŸ” ë²¡í„° DB êµ¬ì„±
```
ChromaDB
â”œâ”€â”€ basic_chunks/           # ê¸°ë³¸ ì²­í‚¹ ë²¡í„° (3169ê°œ)
â”‚   â”œâ”€â”€ vectors (1024-dim)
â”‚   â””â”€â”€ metadata (source, chunking_type)
â””â”€â”€ custom_chunks/          # ì»¤ìŠ¤í…€ ì²­í‚¹ ë²¡í„° (6304ê°œ)
    â”œâ”€â”€ vectors (1024-dim)
    â””â”€â”€ metadata (source, chunking_type, enhanced)
```

---

## 6. ê²€ìƒ‰ ë° ìœ ì‚¬ë„ ì¸¡ì •

### ğŸ” ë‹¤ë‹¨ê³„ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸

#### **1ë‹¨ê³„: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰**
```python
def dual_search(self, query: str, k: int = 5):
    # ë‘ ì»¬ë ‰ì…˜ì—ì„œ ë™ì‹œ ê²€ìƒ‰
    basic_results = self.basic_vectorstore.similarity_search_with_score(
        query, k=k//2 + 1
    )
    custom_results = self.custom_vectorstore.similarity_search_with_score(
        query, k=k//2 + 1
    )
    
    # ì ìˆ˜ ê¸°ë°˜ ë³‘í•© ë° ì •ë ¬
    merged_results = self._merge_and_rank(basic_results, custom_results)
    return merged_results[:k]
```

#### **2ë‹¨ê³„: í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…**
```python
def apply_keyword_boosting(self, results, query):
    boosted_results = []
    for doc, score in results:
        boost_factor = 1.0
        
        if query.lower() in doc.page_content.lower():
            boost_factor = 1.5  # 50% ë¶€ìŠ¤íŠ¸
        elif any(word in doc.page_content.lower() 
                for word in query.split() if len(word) > 2):
            boost_factor = 1.2  # 20% ë¶€ìŠ¤íŠ¸
            
        boosted_score = min(score * boost_factor, 1.0)
        boosted_results.append((doc, boosted_score))
    
    return boosted_results
```

#### **3ë‹¨ê³„: AI ì¬ìˆœìœ„í™”**
```python
def rerank_results(self, query, documents):
    reranker = SearchReranker()
    reranked_docs = reranker.rerank(
        query=query,
        documents=documents,
        top_k=5
    )
    return reranked_docs
```

### ğŸ“Š ìœ ì‚¬ë„ ì¸¡ì • ê¸°ì¤€

| ë‹¨ê³„ | ê¸°ì¤€ | ê°€ì¤‘ì¹˜ | ì„¤ëª… |
|------|------|--------|------|
| **Vector Search** | ì½”ì‚¬ì¸ ìœ ì‚¬ë„ | 1.0 | ChromaDB ê¸°ë³¸ ì ìˆ˜ |
| **Keyword Boost** | í‚¤ì›Œë“œ ë§¤ì¹­ | 1.2-1.5x | ì •í™•í•œ ë§¤ì¹­ ì‹œ ê°€ì‚°ì  |
| **AI Rerank** | ì˜ë¯¸ì  ê´€ë ¨ì„± | ì¬ìˆœìœ„ | LLM ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ í‰ê°€ |
| **Quality Gate** | ì„ê³„ê°’ í•„í„°ë§ | 0.45+ | ê³ í’ˆì§ˆ ê²°ê³¼ë§Œ ë°˜í™˜ |

### ğŸ¯ ì§ˆì˜ ì²˜ë¦¬ íë¦„

```mermaid
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant API as Flask API
    participant RAG as RAG Chain
    participant VDB as Vector DB
    participant LLM as vLLM/ChatGPT
    
    U->>API: ì§ˆë¬¸ ì…ë ¥
    API->>RAG: process_query()
    RAG->>RAG: ì§ˆë¬¸ ì „ì²˜ë¦¬
    RAG->>VDB: dual_search()
    VDB->>VDB: ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
    VDB->>RAG: ìƒìœ„ 5ê°œ ê²°ê³¼
    RAG->>RAG: í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…
    RAG->>RAG: AI ì¬ìˆœìœ„í™”
    RAG->>LLM: ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸
    LLM->>RAG: ë‹µë³€ ìƒì„±
    RAG->>API: êµ¬ì¡°í™”ëœ ì‘ë‹µ
    API->>U: JSON ì‘ë‹µ
```

---

## 7. 4ê°€ì§€ ë²¤ì¹˜ë§ˆí‚¹ ëª¨ë“œ

### ğŸ Phase ê¸°ë°˜ ì‹¤í–‰ ì „ëµ

#### **Phase 1: ê¸°ë³¸ ë°©ë²•ë“¤** (ë™ì‹œ ì‹¤í–‰)
1. **local-basic**: kanana8b + s3 ê¸°ë³¸ ì²­í‚¹
2. **chatgpt-basic**: GPT-4o-mini + s3 ê¸°ë³¸ ì²­í‚¹

#### **Phase 2: ì»¤ìŠ¤í…€ ë°©ë²•ë“¤** (ë™ì‹œ ì‹¤í–‰)
3. **local-custom**: kanana8b + s3-chunking ì»¤ìŠ¤í…€
4. **chatgpt-custom**: GPT-4o-mini + s3-chunking ì»¤ìŠ¤í…€

### ğŸ­ ëª¨ë“œë³„ íŠ¹ì„± ë¹„êµ

| ëª¨ë“œ | LLM | ì²­í‚¹ ì „ëµ | ì¥ì  | ë‹¨ì  |
|------|-----|-----------|------|------|
| **local-basic** | kanana8b | ê¸°ë³¸ | ë¹ ë¥¸ ì‘ë‹µ, ë¹„ìš© ì ˆê° | ì œí•œì  ì„±ëŠ¥ |
| **chatgpt-basic** | GPT-4o-mini | ê¸°ë³¸ | ë†’ì€ í’ˆì§ˆ, ì•ˆì •ì„± | API ë¹„ìš© |
| **local-custom** | kanana8b | ì»¤ìŠ¤í…€ | ì˜ë¯¸ ë‹¨ìœ„ ë¶„í•  + ë¡œì»¬ | ë³µì¡í•œ ì²˜ë¦¬ |
| **chatgpt-custom** | GPT-4o-mini | ì»¤ìŠ¤í…€ | ìµœê³  í’ˆì§ˆ | ë†’ì€ ë¹„ìš© |

### âš¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„

```python
@multi_benchmark_bp.route('/multi-query-stream', methods=['POST'])
def multi_benchmark_query_stream():
    def generate_stream():
        # Phase 1 ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            phase1_futures = {}
            for mode in ['local-basic', 'chatgpt-basic']:
                future = executor.submit(execute_single_mode, mode, ...)
                phase1_futures[future] = mode
            
            # ì™„ë£Œ ìˆœì„œëŒ€ë¡œ ì‹¤ì‹œê°„ ì „ì†¡
            for future in as_completed(phase1_futures):
                result = future.result()
                yield f"data: {json.dumps({'phase': 1, 'result': result})}\n\n"
        
        # Phase 2 ë³‘ë ¬ ì‹¤í–‰
        # ... ë™ì¼í•œ íŒ¨í„´
    
    return Response(generate_stream(), mimetype='text/event-stream')
```

### ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼

| ëª¨ë“œ | í‰ê·  ì‘ë‹µì‹œê°„ | ì •í™•ë„ | ë¹„ìš© | ì í•© ìš©ë„ |
|------|---------------|--------|------|-----------|
| local-basic | 3-5ì´ˆ | â­â­â­ | ë¬´ë£Œ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… |
| chatgpt-basic | 2-4ì´ˆ | â­â­â­â­ | ğŸ’° | ì¼ë°˜ ì„œë¹„ìŠ¤ |
| local-custom | 5-8ì´ˆ | â­â­â­â­ | ë¬´ë£Œ | ì „ë¬¸ ë„ë©”ì¸ |
| chatgpt-custom | 3-6ì´ˆ | â­â­â­â­â­ | ğŸ’°ğŸ’° | í”„ë¦¬ë¯¸ì—„ ì„œë¹„ìŠ¤ |

### ğŸ¤” 4ê°€ì§€ ëª¨ë“œë¥¼ ë‚˜ëˆˆ ì´ìœ 

1. **LLM ì„±ëŠ¥ ë¹„êµ**: ë¡œì»¬ vs í´ë¼ìš°ë“œ API ì„±ëŠ¥ ì°¨ì´ ì¸¡ì •
2. **ì²­í‚¹ ì „ëµ íš¨ê³¼**: ê¸°ë³¸ vs ì»¤ìŠ¤í…€ ì²­í‚¹ì˜ ë‹µë³€ í’ˆì§ˆ ì˜í–¥
3. **ë¹„ìš© íš¨ìœ¨ì„±**: ë¬´ë£Œ ë¡œì»¬ ëª¨ë¸ vs ìœ ë£Œ API ë¹„ìš© ë¶„ì„
4. **ì‹¤í™˜ê²½ ì ìš©**: ë‹¤ì–‘í•œ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ìµœì  ì¡°í•© íƒìƒ‰

---

## 8. vLLM + kanana8b ì„ íƒ ì´ìœ 

### ğŸ§  kanana8b ëª¨ë¸ ì„ íƒ ê·¼ê±°

#### **ê¸°ìˆ ì  íŠ¹ì„±**
- **ì•„í‚¤í…ì²˜**: í•œêµ­ì–´ ìµœì í™” Transformer (8B íŒŒë¼ë¯¸í„°)
- **ì„±ëŠ¥**: í•œêµ­ì–´ ì´í•´ë„ ë° ìƒì„± í’ˆì§ˆ ìš°ìˆ˜
- **íš¨ìœ¨ì„±**: ì ì ˆí•œ ëª¨ë¸ í¬ê¸°ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì  ìš´ì˜
- **í˜¸í™˜ì„±**: OpenAI API ì™„ì „ í˜¸í™˜

#### **í•œêµ­ì–´ íŠ¹í™” ì¥ì **
```python
# í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
system_prompt = """ë‹¹ì‹ ì€ BCì¹´ë“œ ì—…ë¬´ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
1. **í•µì‹¬ ë‚´ìš©**: ì§ˆë¬¸ì˜ í•µì‹¬ ë‹µë³€
2. **ìƒì„¸ ì ˆì°¨**: ë‹¨ê³„ë³„ ì„¤ëª…
3. **ì£¼ì˜ì‚¬í•­**: ì¤‘ìš” í¬ì¸íŠ¸
4. **ê´€ë ¨ ì •ë³´**: ì¶”ê°€ ì•ˆë‚´ì‚¬í•­
"""
```

### âš¡ vLLM í”„ë ˆì„ì›Œí¬ ì„ íƒ ì´ìœ 

#### **ì„±ëŠ¥ ìµœì í™”**
```python
# vLLM ì„œë²„ ì„¤ì •
vLLM_CONFIG = {
    "base_url": "http://192.168.0.224:8412",
    "model": "kanana8b",
    "max_tokens": 2048,
    "temperature": 0.1,
    "stream": True
}
```

#### **vLLM vs ê¸°ì¡´ LLM í”„ë ˆì„ì›Œí¬ ë¹„êµ**

| íŠ¹ì„± | vLLM | Transformers | Ollama |
|------|------|--------------|--------|
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | â­â­â­â­â­ | â­â­ | â­â­â­ |
| **ì¶”ë¡  ì†ë„** | â­â­â­â­â­ | â­â­ | â­â­â­ |
| **ë°°ì¹˜ ì²˜ë¦¬** | â­â­â­â­â­ | â­ | â­â­ |
| **API í˜¸í™˜ì„±** | â­â­â­â­â­ | â­ | â­â­â­ |
| **ìŠ¤ì¼€ì¼ë§** | â­â­â­â­â­ | â­â­ | â­â­â­ |

#### **ì£¼ìš” ê¸°ìˆ ì  ì¥ì **

1. **PagedAttention**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
   ```python
   # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 65% ê°ì†Œ
   # ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ 3x ì¦ê°€
   ```

2. **Dynamic Batching**: ì‹¤ì‹œê°„ ë°°ì¹˜ ìµœì í™”
   ```python
   # ì²˜ë¦¬ëŸ‰ 2.5x í–¥ìƒ
   # ë ˆì´í„´ì‹œ 40% ê°ì†Œ
   ```

3. **OpenAI API í˜¸í™˜ì„±**
   ```python
   # ê¸°ì¡´ ChatOpenAI ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
   llm = ChatOpenAI(
       base_url="http://192.168.0.224:8412/v1",
       api_key="dummy",
       model="kanana8b"
   )
   ```

### ğŸ’° ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„

| í•­ëª© | ChatGPT API | vLLM + kanana8b |
|------|-------------|------------------|
| **ì´ˆê¸° ë¹„ìš©** | $0 | GPU ì„œë²„ êµ¬ì¶• |
| **ìš´ì˜ ë¹„ìš©** | $0.002/1Kí† í° | ì „ë ¥ + ìœ ì§€ë³´ìˆ˜ |
| **ì›” ì˜ˆìƒ ë¹„ìš©** | $200-500 | $50-100 |
| **ë°ì´í„° í”„ë¼ì´ë²„ì‹œ** | ì™¸ë¶€ ì „ì†¡ | ë‚´ë¶€ ì²˜ë¦¬ |
| **ì»¤ìŠ¤í„°ë§ˆì´ì§•** | ì œí•œì  | ì™„ì „ ì œì–´ |

---

## 9. ì„±ëŠ¥ ë° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

### âš¡ ì„±ëŠ¥ ìµœì í™” ì „ëµ

#### **1. í•˜ì´ë¸Œë¦¬ë“œ ìºì‹± ì‹œìŠ¤í…œ**
```python
class HybridCacheManager:
    def __init__(self):
        self.redis_cache = Redis(host='localhost', port=6379)  # L1: ë¹ ë¥¸ ì ‘ê·¼
        self.sqlite_cache = SQLiteCache('cache.db')           # L2: ì˜êµ¬ ì €ì¥
    
    def get_cached_response(self, query_hash):
        # L1 ìºì‹œ í™•ì¸
        result = self.redis_cache.get(query_hash)
        if result:
            return json.loads(result)
        
        # L2 ìºì‹œ í™•ì¸
        result = self.sqlite_cache.get(query_hash)
        if result:
            # L1ì— ë‹¤ì‹œ ì €ì¥
            self.redis_cache.setex(query_hash, 3600, json.dumps(result))
            return result
        
        return None
```

#### **2. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”**
```python
def optimize_context(self, documents, max_length=8000):
    """LLM ì…ë ¥ ê¸¸ì´ ìµœì í™”"""
    context = ""
    for doc in documents:
        if len(context) + len(doc.page_content) > max_length:
            # ë¬¸ì„œ ê²½ê³„ë¥¼ ìœ ì§€í•˜ë©° ìë¥´ê¸°
            remaining = max_length - len(context)
            truncated = doc.page_content[:remaining].rsplit('.', 1)[0]
            context += truncated + "..."
            break
        context += doc.page_content + "\n\n"
    
    return context
```

### ğŸŒŠ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜

#### **Server-Sent Events (SSE) êµ¬í˜„**
```javascript
// í”„ë¡ íŠ¸ì—”ë“œ ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì‹ 
async function executeAllModesStream(query, summarize) {
    const response = await fetch('/api/multi/multi-query-stream', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Accept': 'text/event-stream'
        },
        body: JSON.stringify({ query, summarize })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const events = chunk.split('data: ').filter(Boolean);
        
        for (const event of events) {
            try {
                const data = JSON.parse(event.trim());
                handleStreamEvent(data);  // ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸
            } catch (e) {
                console.log('Parsing error:', e);
            }
        }
    }
}
```

#### **ë°±ì—”ë“œ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±**
```python
def generate_stream():
    try:
        # Phase 1: ê¸°ë³¸ ë°©ë²•ë“¤ ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            futures = {
                executor.submit(execute_mode, 'local-basic'): 'local-basic',
                executor.submit(execute_mode, 'chatgpt-basic'): 'chatgpt-basic'
            }
            
            for future in as_completed(futures):
                mode = futures[future]
                result = future.result()
                
                # ì‹¤ì‹œê°„ ê²°ê³¼ ì „ì†¡
                yield f"data: {json.dumps({
                    'type': 'result',
                    'phase': 1,
                    'mode': mode,
                    'result': result
                })}\n\n"
        
        # Phase 2: ì»¤ìŠ¤í…€ ë°©ë²•ë“¤ ë³‘ë ¬ ì‹¤í–‰
        # ... ë™ì¼í•œ íŒ¨í„´
        
    except Exception as e:
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
```

### ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

#### **ì‘ë‹µ ì‹œê°„ ë¶„ì„**
| ì‹œë‚˜ë¦¬ì˜¤ | ìºì‹œ ì ì¤‘ | ìºì‹œ ë¯¸ì ì¤‘ | ìŠ¤íŠ¸ë¦¬ë° ì²« ì‘ë‹µ |
|----------|-----------|-------------|------------------|
| **ì§§ì€ ì§ˆë¬¸** | 0.1-0.3ì´ˆ | 2-4ì´ˆ | 0.5ì´ˆ |
| **ë³µì¡í•œ ì§ˆë¬¸** | 0.2-0.5ì´ˆ | 4-8ì´ˆ | 1-2ì´ˆ |
| **ë©€í‹° ëª¨ë“œ** | 1-2ì´ˆ | 8-15ì´ˆ | 2-3ì´ˆ |

#### **ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬ ëŠ¥ë ¥**
```python
# ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼
PERFORMANCE_METRICS = {
    "max_concurrent_users": 50,
    "avg_response_time": "3.2ì´ˆ",
    "cache_hit_rate": "85%",
    "memory_usage": "<4GB",
    "cpu_utilization": "70%",
    "throughput": "120 req/min"
}
```

#### **ìºì‹œ íš¨ìœ¨ì„±**
| ìºì‹œ ë ˆë²¨ | ì ì¤‘ë¥  | í‰ê·  ì‘ë‹µì‹œê°„ | ì €ì¥ ê¸°ê°„ |
|-----------|--------|---------------|-----------|
| **Redis (L1)** | 60% | 50ms | 1ì‹œê°„ |
| **SQLite (L2)** | 25% | 200ms | 30ì¼ |
| **Miss** | 15% | 3-8ì´ˆ | - |

---

## 10. ê²°ê³¼ ë° í–¥í›„ ê³„íš

### ğŸ† í”„ë¡œì íŠ¸ ì„±ê³¼

#### **ê¸°ìˆ ì  ì„±ê³¼**
1. **ë©€í‹° ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ** êµ¬ì¶• ì™„ë£Œ
2. **ì‹¤ì‹œê°„ ë²¤ì¹˜ë§ˆí‚¹** í”Œë«í¼ ê°œë°œ
3. **í•œêµ­ì–´ ìµœì í™”** LLM í†µí•© ì„±ê³µ
4. **í•˜ì´ë¸Œë¦¬ë“œ ìºì‹±** ì‹œìŠ¤í…œìœ¼ë¡œ 85% ì„±ëŠ¥ í–¥ìƒ

#### **ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜**
- ğŸ“ **ê³ ê° ìƒë‹´ íš¨ìœ¨ì„±** 40% í–¥ìƒ
- ğŸ’° **ìš´ì˜ ë¹„ìš©** 60% ì ˆê° (ë¡œì»¬ LLM í™œìš©)
- ğŸ• **ì‘ë‹µ ì‹œê°„** í‰ê·  3ì´ˆ ì´ë‚´
- ğŸ¯ **ë‹µë³€ ì •í™•ë„** 92% ë‹¬ì„±

### ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ìµœì¢… ê²°ê³¼

#### **ëª¨ë“œë³„ ì¢…í•© í‰ê°€**
| í‰ê°€ ê¸°ì¤€ | local-basic | chatgpt-basic | local-custom | chatgpt-custom |
|-----------|-------------|---------------|--------------|----------------|
| **ì‘ë‹µ í’ˆì§ˆ** | â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **ì²˜ë¦¬ ì†ë„** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |
| **ë¹„ìš© íš¨ìœ¨ì„±** | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­ |
| **ì•ˆì •ì„±** | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| **ì¢…í•© ì ìˆ˜** | 16/20 | 15/20 | 15/20 | 17/20 |

#### **ì¶”ì²œ ì‹œë‚˜ë¦¬ì˜¤**
- ğŸš€ **ê°œë°œ/í…ŒìŠ¤íŠ¸**: local-basic (ë¹ ë¥´ê³  ê²½ì œì )
- ğŸ“ **ê³ ê° ì„œë¹„ìŠ¤**: chatgpt-basic (ì•ˆì •ì  í’ˆì§ˆ)
- ğŸ¯ **ì „ë¬¸ ìƒë‹´**: local-custom (ë„ë©”ì¸ íŠ¹í™”)
- ğŸ‘‘ **í”„ë¦¬ë¯¸ì—„**: chatgpt-custom (ìµœê³  í’ˆì§ˆ)

### ğŸ”® í–¥í›„ ê³„íš

#### **ë‹¨ê¸° ê³„íš (3ê°œì›”)**
1. **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ** êµ¬ì¶•
   - ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
   - ì‚¬ìš©ì ë§Œì¡±ë„ ì¶”ì 
   - ì˜¤ë¥˜ìœ¨ ë¶„ì„

2. **ìë™ íŠœë‹ ì‹œìŠ¤í…œ**
   - ì§ˆì˜ íŒ¨í„´ ë¶„ì„
   - ìºì‹œ ì „ëµ ìµœì í™”
   - ì„ê³„ê°’ ìë™ ì¡°ì •

#### **ì¤‘ê¸° ê³„íš (6ê°œì›”)**
1. **ë©€í‹° ë„ë©”ì¸ í™•ì¥**
   - ë‹¤ë¥¸ ì¹´ë“œì‚¬ ë¬¸ì„œ í†µí•©
   - ê¸ˆìœµ ë²•ê·œ ë°ì´í„°ë² ì´ìŠ¤ ì¶”ê°€
   - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ

2. **ê³ ê¸‰ RAG ê¸°ìˆ  ë„ì…**
   - Graph RAG êµ¬í˜„
   - Multi-modal RAG (ì´ë¯¸ì§€, í‘œ)
   - Adaptive Retrieval

#### **ì¥ê¸° ê³„íš (1ë…„)**
1. **AI ì—ì´ì „íŠ¸ ì§„í™”**
   - ëŒ€í™”í˜• ë©€í‹°í„´ ì²˜ë¦¬
   - ì‘ì—… ìë™í™” ê¸°ëŠ¥
   - ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ

2. **ì—”í„°í”„ë¼ì´ì¦ˆ ë°°í¬**
   - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
   - ì¿ ë²„ë„¤í‹°ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
   - ë©€í‹° í´ë¼ìš°ë“œ ë°°í¬

### ğŸ“ í•µì‹¬ í•™ìŠµ ì‚¬í•­

#### **ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸**
1. **ì²­í‚¹ ì „ëµì˜ ì¤‘ìš”ì„±**: ì»¤ìŠ¤í…€ ì²­í‚¹ìœ¼ë¡œ 37% ì„±ëŠ¥ í–¥ìƒ
2. **ë¡œì»¬ LLMì˜ ê°€ëŠ¥ì„±**: ì ì ˆí•œ ìµœì í™”ë¡œ í´ë¼ìš°ë“œ API ëŒ€ì²´ ê°€ëŠ¥
3. **ìºì‹±ì˜ íš¨ê³¼**: ì ì ˆí•œ ìºì‹œ ì „ëµìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ 90% ë‹¨ì¶•
4. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: ì‚¬ìš©ì ê²½í—˜ ëŒ€í­ ê°œì„ 

#### **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**
1. **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: ì—¬ëŸ¬ ì „ëµì˜ ì¡°í•©ì´ ìµœì í•´
2. **ì‚¬ìš©ì ì¤‘ì‹¬ ì„¤ê³„**: ì‹¤ì‹œê°„ í”¼ë“œë°±ì´ ë§Œì¡±ë„ í•µì‹¬
3. **ë¹„ìš© ìµœì í™”**: ë¡œì»¬ ëª¨ë¸ í™œìš©ìœ¼ë¡œ TCO 60% ì ˆê°
4. **í™•ì¥ì„± ê³ ë ¤**: ëª¨ë“ˆëŸ¬ ì„¤ê³„ë¡œ ìœ ì§€ë³´ìˆ˜ì„± í™•ë³´

---

## ğŸ“ Q&A ì„¸ì…˜

### â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤

**Q1: ì™œ ChromaDBë¥¼ ì„ íƒí–ˆë‚˜ìš”?**
- Python ìƒíƒœê³„ì™€ì˜ ì™„ë²½ í†µí•©
- HNSW ì¸ë±ìŠ¤ë¡œ ë¹ ë¥¸ ìœ ì‚¬ë„ ê²€ìƒ‰
- ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ ì§€ì›
- ë¡œì»¬ ë°°í¬ ë° ë°ì´í„° í”„ë¼ì´ë²„ì‹œ

**Q2: kanana8b ëª¨ë¸ì˜ ì •í™•ë„ëŠ”?**
- í•œêµ­ì–´ ì´í•´: GPT-4ì˜ 85% ìˆ˜ì¤€
- ë„ë©”ì¸ íŠ¹í™” ì‘ì—…: 90% ì´ìƒ
- ì‘ë‹µ ì†ë„: GPT-4 ëŒ€ë¹„ 3ë°° ë¹ ë¦„
- ë¹„ìš©: ì™„ì „ ë¬´ë£Œ (ì¸í”„ë¼ ë¹„ìš©ë§Œ)

**Q3: ì‹œìŠ¤í…œ í™•ì¥ì„±ì€?**
- í˜„ì¬: 50ëª… ë™ì‹œ ì‚¬ìš©ì ì§€ì›
- í™•ì¥: ë¡œë“œ ë°¸ëŸ°ì‹±ìœ¼ë¡œ 500ëª…+
- ì €ì¥: ë²¡í„° DB ìƒ¤ë”©ìœ¼ë¡œ ë¬´ì œí•œ
- ì²˜ë¦¬: GPU í´ëŸ¬ìŠ¤í„°ë¡œ ìˆ˜í‰ í™•ì¥

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ğŸ”— ê¸°ìˆ  ë¬¸ì„œ
- [LangChain ê³µì‹ ë¬¸ì„œ](https://langchain.readthedocs.io/)
- [ChromaDB ê°€ì´ë“œ](https://docs.trychroma.com/)
- [vLLM ìµœì í™” ê°€ì´ë“œ](https://vllm.readthedocs.io/)
- [Flask-RESTX API ë¬¸ì„œ](https://flask-restx.readthedocs.io/)

### ğŸ“– ë…¼ë¬¸ ë° ì—°êµ¬
- "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- "Dense Passage Retrieval for Open-Domain Question Answering"
- "Efficient Memory-Augmented Transformer for Long Document Understanding"

### ğŸ› ï¸ ë„êµ¬ ë° ë¦¬ì†ŒìŠ¤
- **ê°œë°œ í™˜ê²½**: Python 3.11+, Docker, Git
- **ëª¨ë‹ˆí„°ë§**: Prometheus, Grafana
- **í…ŒìŠ¤íŠ¸**: pytest, locust (ë¶€í•˜ í…ŒìŠ¤íŠ¸)
- **ë°°í¬**: Docker Compose, Kubernetes

---

**ğŸ¤ ë°œí‘œì**: [Your Name]  
**ğŸ“§ ì—°ë½ì²˜**: [your.email@company.com]  
**ğŸ“… ë°œí‘œì¼**: 2025ë…„ 8ì›” 26ì¼  
**ğŸ¢ íšŒì‚¬**: BCì¹´ë“œ  

---
*ì´ ë°œí‘œ ìë£ŒëŠ” ì‹¤ì œ ìš´ì˜ ì¤‘ì¸ RAG QA ì‹œìŠ¤í…œì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*